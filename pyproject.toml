[tool.poetry]
name = "triton-nautilus"
version = "0.1.0"
description = "Launching triton inference servers with kubernetes"
authors = ["Ethan Jacob Marx <ethan.marx@ligo.org>"]
license = "MIT"

[tool.poetry.scripts]
export-and-launch-triton = "triton_nautilus.main:main"


[tool.poetry.dependencies]
python = ">=3.8,<3.11"

torch = {version = "^1.10", source = "torch"}
s3fs = "^2023.10.0"
ml4gw = "^0.2.0"

# hard-pin the tensorrt version for compatability with
# Triton. This corresponds to Triton container 22.12-py3
tensorrt = "8.5.1.7"

[tool.poetry.dependencies."hermes.quiver"]
path = "./hermes/hermes/hermes.quiver"
develop = true

[tool.poetry.dev-dependencies]
pytest = "^7.3"

[[tool.poetry.source]]
name = "torch"
url = "https://download.pytorch.org/whl/cpu"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"
